{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b09b9b1-ae41-4a2e-b746-1d1cb7908182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachdved/miniconda3/envs/local_llm_host/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 23 00:57:52 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.119.02             Driver Version: 580.119.02     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5090        Off |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   31C    P3             46W /  450W |     150MiB /  32607MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2681      G   /usr/bin/kwin_wayland                    50MiB |\n",
      "|    0   N/A  N/A            2780      G   /usr/bin/Xwayland                         8MiB |\n",
      "|    0   N/A  N/A            2859      G   /usr/bin/plasmashell                      6MiB |\n",
      "|    0   N/A  N/A            4053      G   /usr/libexec/kscreenlocker_greet          6MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from ml_modules import *\n",
    "from sequence_modules import *\n",
    "from llm_modules import *\n",
    "from agent import *\n",
    "from simulation import *\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from ml_ops_utils import *\n",
    "\n",
    "import gc\n",
    "\n",
    "from hand_strength import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5de477-9eec-4a53-a3db-98cfc96b5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_players = 2  # or up to 8\n",
    "embed_dim = 256\n",
    "max_seq_len = 1024\n",
    "num_streets = 4\n",
    "device = \"cuda\"\n",
    "\n",
    "hand_counter = 0  # track globally across hands\n",
    "batch_size=1024\n",
    "small_blind = 1\n",
    "big_blind = 2\n",
    "starting_stack_sizes = 400\n",
    "\n",
    "losses = {0 : [], 1: []}\n",
    "winnings = {0 : [0], 1 : [0]}\n",
    "\n",
    "action_validator = PokerActionValidator(\n",
    "    num_players = num_players,\n",
    "    small_blind = small_blind,\n",
    "    big_blind = big_blind,\n",
    "    starting_stack_sizes = starting_stack_sizes\n",
    ")\n",
    "\n",
    "def build_player_components(num_players, embed_dim, max_seq_len, num_streets, device):\n",
    "    return {\n",
    "        \"street_embedder\": StreetPositionalEncoding(num_streets=num_streets, embedding_dim=embed_dim, max_seq_len=max_seq_len, device=device),\n",
    "        \"table_position_embedder\": TablePositionalEncoding(num_players=num_players, embedding_dim=embed_dim, max_seq_len=max_seq_len, device=device),\n",
    "        \"action_embedder\": ActionEncoding(embedding_dim=embed_dim, max_seq_len=max_seq_len, device=device),\n",
    "        \"pot_size_embedder\": PotSizeSequenceEmbedder(max_seq_len=max_seq_len, pad_value=-1, device=device),\n",
    "        \"poker_sequence_embedder\": PokerSequenceEmbedder(\n",
    "            street_input_dimension=embed_dim,\n",
    "            table_position_input_dimension=embed_dim,\n",
    "            action_input_dimension=embed_dim,\n",
    "            latent_dimensions=[embed_dim, embed_dim * 2, embed_dim * 4, embed_dim * 8],\n",
    "            device=device\n",
    "        ),\n",
    "        \"cards\": Cards(device=device),\n",
    "        \"self_position_embedder\": SelfPositionEmbedder(number_of_positions=num_players, device=device),\n",
    "    }\n",
    "\n",
    "players = [build_player_components(num_players, embed_dim, max_seq_len, num_streets, device) for _ in range(num_players)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f758e4e-f5ed-4ef2-b815-ded7288bea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.78it/s]\n",
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
       "          (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"./models/qwen3-1point7b/\"\n",
    "\n",
    "tokenizer, model = load_model(model_name)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea583fcf-76eb-40ae-a082-a107b756d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(num_players, embed_dim, max_seq_len, num_streets, device, model):\n",
    "    self_position_embedder = SelfPositionEmbedder(number_of_positions=num_players, device=device)\n",
    "    \n",
    "    cards = Cards(device=device)\n",
    "    street_embedder = StreetPositionalEncoding(num_streets=num_streets, embedding_dim=embed_dim, max_seq_len=max_seq_len, device=device)\n",
    "    table_position_embedder = TablePositionalEncoding(num_players=num_players, embedding_dim=embed_dim, max_seq_len=max_seq_len, device=device)\n",
    "    action_embedder = ActionEncoding(embedding_dim=embed_dim, max_seq_len=max_seq_len, device=device)\n",
    "    pot_size_embedder = PotSizeSequenceEmbedder(max_seq_len=max_seq_len, pad_value=-1, device=device)\n",
    "    poker_sequence_embedder = PokerSequenceEmbedder(\n",
    "        street_input_dimension=embed_dim,\n",
    "        table_position_input_dimension=embed_dim,\n",
    "        action_input_dimension=embed_dim,\n",
    "        latent_dimensions=[embed_dim, embed_dim * 2, embed_dim * 4, embed_dim * 8],\n",
    "        device=device\n",
    "    )\n",
    "    policy_model = PolicyModel(\n",
    "        num_players=num_players,\n",
    "        self_position_embedder=self_position_embedder,\n",
    "        active_players_hidden_dims=[1024, 2048],\n",
    "        stack_size_hidden_dims=[1024, 2048],\n",
    "        card_embeddings_hidden_dims=[2048, 2048],\n",
    "        final_output_hidden_dims=[1024, 512, 256],\n",
    "        value_output_hidden_dims=[1024, 512, 256],\n",
    "        dropout_rate=0,\n",
    "        device=device,\n",
    "    )\n",
    "    agent = PokerAgent(\n",
    "        cards,\n",
    "        street_embedder,\n",
    "        table_position_embedder,\n",
    "        action_embedder,\n",
    "        pot_size_embedder,\n",
    "        poker_sequence_embedder,\n",
    "        model,\n",
    "        policy_model,\n",
    "        device=device,\n",
    "        llm_train=False\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "population_size = num_players  # or set independently, e.g. 8\n",
    "agents = [build_agent(num_players, embed_dim, max_seq_len, num_streets, device, model) for _ in range(population_size)]\n",
    "optimizers = [torch.optim.AdamW(agent.parameters(), lr=1e-4) for agent in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95de4db0-14db-4cbc-a796-0f21f53ccfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AdamW (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     decoupled_weight_decay: True\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.0001\n",
       "     maximize: False\n",
       "     weight_decay: 0.01\n",
       " ),\n",
       " AdamW (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     decoupled_weight_decay: True\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.0001\n",
       "     maximize: False\n",
       "     weight_decay: 0.01\n",
       " )]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b48229ce-6683-4603-8a18-1ca7b74d612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_cards_at_front(deck, card_values):\n",
    "    \"\"\"Force specific cards to the front of the deck (e.g. for testing specific hands).\"\"\"\n",
    "    deck = deck.clone()\n",
    "    for i, card_val in enumerate(card_values):\n",
    "        current_pos = torch.where(deck == card_val)[1]\n",
    "        deck[0, current_pos] = deck[0, i].clone()\n",
    "        deck[0, i] = card_val\n",
    "    return deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7d3c20-71c9-4fb8-a9bd-6504f09724fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hand(num_players, batch_size, agents, small_blind, big_blind, starting_stack_sizes, hand_counter, max_seq_len, device='cuda'):\n",
    "    #deck_order_shuffled = torch.argsort(torch.rand(1, 52))\n",
    "\n",
    "    # Round-robin: rotate which agents sit in which seats each hand\n",
    "    population_size = len(agents)\n",
    "    #seated_agents = [agents[(hand_counter + i) % population_size] for i in range(num_players)]\n",
    "    seated_agents = [agents[(i) % population_size] for i in range(num_players)]\n",
    "    \n",
    "    # Sequence buffers\n",
    "    street_idxs = (torch.zeros((batch_size, max_seq_len)) + num_streets + 2).long()\n",
    "    table_position_idxs = (torch.zeros((batch_size, max_seq_len)) + num_players).long()\n",
    "    action_idxs = (torch.zeros((batch_size, max_seq_len)) + 21).long()\n",
    "    pot_size_sequence = torch.zeros((batch_size, max_seq_len)) - 1\n",
    "\n",
    "    # Blind postings (seat 0=SB, seat 1=BB always)\n",
    "    street_idxs[:, :2] = 0\n",
    "    table_position_idxs[:, 0] = 0\n",
    "    table_position_idxs[:, 1] = 1\n",
    "    action_idxs[:, 0] = 0  # post SB\n",
    "    action_idxs[:, 1] = 1  # post BB\n",
    "    pot_size_sequence[:, 0] = small_blind\n",
    "    pot_size_sequence[:, 1] = small_blind + big_blind\n",
    "\n",
    "    # Stack sizes\n",
    "    stack_sizes_init = [\n",
    "        starting_stack_sizes - small_blind if i == 0\n",
    "        else starting_stack_sizes - big_blind if i == 1\n",
    "        else starting_stack_sizes\n",
    "        for i in range(num_players)\n",
    "    ]\n",
    "    active_players = torch.ones((batch_size, num_players))\n",
    "    stack_size = torch.Tensor(stack_sizes_init).unsqueeze(0).tile(batch_size, 1)\n",
    "\n",
    "    # Deal hole cards\n",
    "    player_cards = []\n",
    "    for i in range(num_players):\n",
    "        cards = torch.zeros((batch_size, 2, 7), dtype=torch.long, device=device)\n",
    "        card_indices = deck_order_shuffled[0, i*2 : i*2+2]\n",
    "        cards[:, 0, :2] = card_indices % 13   # rank\n",
    "        cards[:, 1, :2] = card_indices // 13  # suit\n",
    "        cards[:, 0, 2:] = 13  # padding rank\n",
    "        cards[:, 1, 2:] = 4   # padding suit\n",
    "        player_cards.append(cards)\n",
    "\n",
    "    # Build table with round-robin seated agents\n",
    "    table = {\n",
    "        i: [seated_agents[i], player_cards[i], torch.Tensor([i]).to(device).tile(batch_size)]\n",
    "        for i in range(num_players)\n",
    "    }\n",
    "\n",
    "    return (\n",
    "        street_idxs,\n",
    "        table_position_idxs,\n",
    "        action_idxs,\n",
    "        pot_size_sequence,\n",
    "        active_players,\n",
    "        stack_size,\n",
    "        table,\n",
    "        deck_order_shuffled,\n",
    "        seated_agents,  # return so you know who played which seat for gradient updates\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eeb4cd5-7cb0-40f8-9fc6-3cc8e2515bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_probs(player_idx, player_action_batch_indices, player_masks, sim_table, sim_street_idxs, sim_table_position_idxs, sim_action_idxs, sim_pot_size_sequence, sim_active_players, sim_stack_size):\n",
    "    batch_indices = player_action_batch_indices[player_idx]\n",
    "    \n",
    "    if batch_indices.numel() == 0:\n",
    "        return None\n",
    "    \n",
    "    mask = player_masks[player_idx]\n",
    "    position = sim_table[player_idx][2][batch_indices]\n",
    "    cards = sim_table[player_idx][1][batch_indices]\n",
    "    street_idxs = sim_street_idxs[batch_indices]\n",
    "    table_position_idxs = sim_table_position_idxs[batch_indices]\n",
    "    action_idxs = sim_action_idxs[batch_indices]\n",
    "    pot_size_sequence = sim_pot_size_sequence[batch_indices]\n",
    "    active_players = sim_active_players[batch_indices]\n",
    "    stack_size = sim_stack_size[batch_indices]\n",
    "\n",
    "    outputs = agents[player_idx](\n",
    "        position,\n",
    "        cards,\n",
    "        street_idxs,\n",
    "        table_position_idxs,\n",
    "        action_idxs,\n",
    "        pot_size_sequence,\n",
    "        active_players.to('cuda'),\n",
    "        stack_size.to('cuda')\n",
    "    )\n",
    "\n",
    "    taken_actions = sim_action_idxs[batch_indices + 1, mask - 1]\n",
    "    log_probs = torch.nn.functional.log_softmax(outputs['probits'], dim=-1)\n",
    "    log_probs_of_taken_actions = log_probs[torch.arange(log_probs.shape[0]), taken_actions]\n",
    "    return log_probs_of_taken_actions\n",
    "\n",
    "\n",
    "def compute_loss_and_step(player_idx, player_log_probs, sim_table, optimizers, entropy_coef=0.01):\n",
    "    log_probs = player_log_probs[player_idx]\n",
    "    \n",
    "    if log_probs is None:\n",
    "        return None\n",
    "    \n",
    "    rewards = sim_table[player_idx][-1]\n",
    "    \n",
    "    entropy = -(log_probs * log_probs.exp()).sum(dim=-1).mean()\n",
    "    loss = -(log_probs * rewards).mean() - entropy_coef * entropy\n",
    "    loss.backward()\n",
    "    optimizers[player_idx].step()\n",
    "    optimizers[player_idx].zero_grad()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742771eb-3459-402a-bc69-c3c1ecda5347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting everything started\n",
      "  Allocated: 4.10 GB\n",
      "  Reserved:  4.18 GB\n",
      "\n",
      "Step 0 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 1 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 2 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 3 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0, 2131.0, 2133.0, 2135.0, 2137.0, 2139.0, 2141.0, 2143.0, 2145.0, 2147.0, 2149.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0, -2131.0, -2133.0, -2135.0, -2137.0, -2139.0, -2141.0, -2143.0, -2145.0, -2147.0, -2149.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 4 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0, 2131.0, 2133.0, 2135.0, 2137.0, 2139.0, 2141.0, 2143.0, 2145.0, 2147.0, 2149.0, 2151.0, 2153.0, 2155.0, 2157.0, 2159.0, 2161.0, 2163.0, 2165.0, 2167.0, 2169.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0, -2131.0, -2133.0, -2135.0, -2137.0, -2139.0, -2141.0, -2143.0, -2145.0, -2147.0, -2149.0, -2151.0, -2153.0, -2155.0, -2157.0, -2159.0, -2161.0, -2163.0, -2165.0, -2167.0, -2169.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 5 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0, 2131.0, 2133.0, 2135.0, 2137.0, 2139.0, 2141.0, 2143.0, 2145.0, 2147.0, 2149.0, 2151.0, 2153.0, 2155.0, 2157.0, 2159.0, 2161.0, 2163.0, 2165.0, 2167.0, 2169.0, 2171.0, 2173.0, 2175.0, 2177.0, 2179.0, 2181.0, 2183.0, 2185.0, 2187.0, 2189.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0, -2131.0, -2133.0, -2135.0, -2137.0, -2139.0, -2141.0, -2143.0, -2145.0, -2147.0, -2149.0, -2151.0, -2153.0, -2155.0, -2157.0, -2159.0, -2161.0, -2163.0, -2165.0, -2167.0, -2169.0, -2171.0, -2173.0, -2175.0, -2177.0, -2179.0, -2181.0, -2183.0, -2185.0, -2187.0, -2189.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 6 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0, 2131.0, 2133.0, 2135.0, 2137.0, 2139.0, 2141.0, 2143.0, 2145.0, 2147.0, 2149.0, 2151.0, 2153.0, 2155.0, 2157.0, 2159.0, 2161.0, 2163.0, 2165.0, 2167.0, 2169.0, 2171.0, 2173.0, 2175.0, 2177.0, 2179.0, 2181.0, 2183.0, 2185.0, 2187.0, 2189.0, 2191.0, 2193.0, 2195.0, 2197.0, 2199.0, 2201.0, 2203.0, 2205.0, 2207.0, 2209.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0, -2131.0, -2133.0, -2135.0, -2137.0, -2139.0, -2141.0, -2143.0, -2145.0, -2147.0, -2149.0, -2151.0, -2153.0, -2155.0, -2157.0, -2159.0, -2161.0, -2163.0, -2165.0, -2167.0, -2169.0, -2171.0, -2173.0, -2175.0, -2177.0, -2179.0, -2181.0, -2183.0, -2185.0, -2187.0, -2189.0, -2191.0, -2193.0, -2195.0, -2197.0, -2199.0, -2201.0, -2203.0, -2205.0, -2207.0, -2209.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 7 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0, 2131.0, 2133.0, 2135.0, 2137.0, 2139.0, 2141.0, 2143.0, 2145.0, 2147.0, 2149.0, 2151.0, 2153.0, 2155.0, 2157.0, 2159.0, 2161.0, 2163.0, 2165.0, 2167.0, 2169.0, 2171.0, 2173.0, 2175.0, 2177.0, 2179.0, 2181.0, 2183.0, 2185.0, 2187.0, 2189.0, 2191.0, 2193.0, 2195.0, 2197.0, 2199.0, 2201.0, 2203.0, 2205.0, 2207.0, 2209.0, 2211.0, 2213.0, 2215.0, 2217.0, 2219.0, 2221.0, 2223.0, 2225.0, 2227.0, 2229.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0, -2131.0, -2133.0, -2135.0, -2137.0, -2139.0, -2141.0, -2143.0, -2145.0, -2147.0, -2149.0, -2151.0, -2153.0, -2155.0, -2157.0, -2159.0, -2161.0, -2163.0, -2165.0, -2167.0, -2169.0, -2171.0, -2173.0, -2175.0, -2177.0, -2179.0, -2181.0, -2183.0, -2185.0, -2187.0, -2189.0, -2191.0, -2193.0, -2195.0, -2197.0, -2199.0, -2201.0, -2203.0, -2205.0, -2207.0, -2209.0, -2211.0, -2213.0, -2215.0, -2217.0, -2219.0, -2221.0, -2223.0, -2225.0, -2227.0, -2229.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 8 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0, 2131.0, 2133.0, 2135.0, 2137.0, 2139.0, 2141.0, 2143.0, 2145.0, 2147.0, 2149.0, 2151.0, 2153.0, 2155.0, 2157.0, 2159.0, 2161.0, 2163.0, 2165.0, 2167.0, 2169.0, 2171.0, 2173.0, 2175.0, 2177.0, 2179.0, 2181.0, 2183.0, 2185.0, 2187.0, 2189.0, 2191.0, 2193.0, 2195.0, 2197.0, 2199.0, 2201.0, 2203.0, 2205.0, 2207.0, 2209.0, 2211.0, 2213.0, 2215.0, 2217.0, 2219.0, 2221.0, 2223.0, 2225.0, 2227.0, 2229.0, 2231.0, 2233.0, 2235.0, 2237.0, 2239.0, 2241.0, 2243.0, 2245.0, 2247.0, 2249.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0, -2131.0, -2133.0, -2135.0, -2137.0, -2139.0, -2141.0, -2143.0, -2145.0, -2147.0, -2149.0, -2151.0, -2153.0, -2155.0, -2157.0, -2159.0, -2161.0, -2163.0, -2165.0, -2167.0, -2169.0, -2171.0, -2173.0, -2175.0, -2177.0, -2179.0, -2181.0, -2183.0, -2185.0, -2187.0, -2189.0, -2191.0, -2193.0, -2195.0, -2197.0, -2199.0, -2201.0, -2203.0, -2205.0, -2207.0, -2209.0, -2211.0, -2213.0, -2215.0, -2217.0, -2219.0, -2221.0, -2223.0, -2225.0, -2227.0, -2229.0, -2231.0, -2233.0, -2235.0, -2237.0, -2239.0, -2241.0, -2243.0, -2245.0, -2247.0, -2249.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n",
      "Step 9 | winnings: {0: [0, 2.0, 1.0, 3.0, 403.0, 667.0, 666.0, 1066.0, 1466.0, 1689.0, 2089.0, 2091.0, 2093.0, 2095.0, 2097.0, 2099.0, 2101.0, 2103.0, 2105.0, 2107.0, 2109.0, 2111.0, 2113.0, 2115.0, 2117.0, 2119.0, 2121.0, 2123.0, 2125.0, 2127.0, 2129.0, 2131.0, 2133.0, 2135.0, 2137.0, 2139.0, 2141.0, 2143.0, 2145.0, 2147.0, 2149.0, 2151.0, 2153.0, 2155.0, 2157.0, 2159.0, 2161.0, 2163.0, 2165.0, 2167.0, 2169.0, 2171.0, 2173.0, 2175.0, 2177.0, 2179.0, 2181.0, 2183.0, 2185.0, 2187.0, 2189.0, 2191.0, 2193.0, 2195.0, 2197.0, 2199.0, 2201.0, 2203.0, 2205.0, 2207.0, 2209.0, 2211.0, 2213.0, 2215.0, 2217.0, 2219.0, 2221.0, 2223.0, 2225.0, 2227.0, 2229.0, 2231.0, 2233.0, 2235.0, 2237.0, 2239.0, 2241.0, 2243.0, 2245.0, 2247.0, 2249.0, 2251.0, 2253.0, 2255.0, 2257.0, 2259.0, 2261.0, 2263.0, 2265.0, 2267.0, 2269.0], 1: [0, -2.0, -1.0, -3.0, -403.0, -667.0, -666.0, -1066.0, -1466.0, -1689.0, -2089.0, -2091.0, -2093.0, -2095.0, -2097.0, -2099.0, -2101.0, -2103.0, -2105.0, -2107.0, -2109.0, -2111.0, -2113.0, -2115.0, -2117.0, -2119.0, -2121.0, -2123.0, -2125.0, -2127.0, -2129.0, -2131.0, -2133.0, -2135.0, -2137.0, -2139.0, -2141.0, -2143.0, -2145.0, -2147.0, -2149.0, -2151.0, -2153.0, -2155.0, -2157.0, -2159.0, -2161.0, -2163.0, -2165.0, -2167.0, -2169.0, -2171.0, -2173.0, -2175.0, -2177.0, -2179.0, -2181.0, -2183.0, -2185.0, -2187.0, -2189.0, -2191.0, -2193.0, -2195.0, -2197.0, -2199.0, -2201.0, -2203.0, -2205.0, -2207.0, -2209.0, -2211.0, -2213.0, -2215.0, -2217.0, -2219.0, -2221.0, -2223.0, -2225.0, -2227.0, -2229.0, -2231.0, -2233.0, -2235.0, -2237.0, -2239.0, -2241.0, -2243.0, -2245.0, -2247.0, -2249.0, -2251.0, -2253.0, -2255.0, -2257.0, -2259.0, -2261.0, -2263.0, -2265.0, -2267.0, -2269.0]}\n",
      "Finished up one gradient step\n",
      "  Allocated: 5.09 GB\n",
      "  Reserved:  5.52 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory(\"Getting everything started\")\n",
    "num_rollouts = 10\n",
    "entropy_coef = 0.1\n",
    "for outer_step in range(10):\n",
    "    all_hand_inputs = []\n",
    "    all_rewards = {}\n",
    "\n",
    "    # --- rollout collection phase (no graphs retained) ---\n",
    "    for _ in range(num_rollouts):\n",
    "        deck_order_shuffled = torch.argsort(torch.rand(1, 52))\n",
    "        deck_order_shuffled = place_cards_at_front(deck_order_shuffled, [12, 25, 0, 18])\n",
    "\n",
    "        street_idxs, table_position_idxs, action_idxs, pot_size_sequence, \\\n",
    "        active_players, stack_size, table, deck_order_shuffled, seated_agents = build_hand(\n",
    "            num_players, batch_size, agents, small_blind, big_blind,\n",
    "            starting_stack_sizes, hand_counter, max_seq_len, device\n",
    "        )\n",
    "\n",
    "        (sim_street_idxs, sim_table_position_idxs, sim_action_idxs,\n",
    "         sim_pot_size_sequence, sim_active_players, sim_stack_size, sim_table) = simulate_hand(\n",
    "            num_players, street_idxs, table_position_idxs, action_idxs, pot_size_sequence,\n",
    "            active_players, stack_size, table, action_validator, deck_order_shuffled,\n",
    "        )\n",
    "        hand_counter += 1\n",
    "\n",
    "        rewards = determine_winner(\n",
    "            sim_active_players[-1],\n",
    "            sim_pot_size_sequence[-1],\n",
    "            sim_stack_size[-1],\n",
    "            sim_table\n",
    "        )\n",
    "\n",
    "        next_to_act = action_validator.get_next_to_act(\n",
    "            sim_street_idxs, sim_table_position_idxs,\n",
    "            sim_action_idxs, sim_active_players\n",
    "        )\n",
    "        player_action_batch_indices = {\n",
    "            i: torch.where(next_to_act == i)[0] for i in range(num_players)\n",
    "        }\n",
    "        player_masks = {\n",
    "            i: (sim_action_idxs[player_action_batch_indices[i] + 1] == 21).float().argmax(dim=1)\n",
    "            for i in range(num_players)\n",
    "            if player_action_batch_indices[i].numel() > 0\n",
    "        }\n",
    "\n",
    "        all_hand_inputs.append({\n",
    "            'player_action_batch_indices': player_action_batch_indices,\n",
    "            'player_masks': player_masks,\n",
    "            'sim_table': [[elem.detach() if isinstance(elem, torch.Tensor) else elem\n",
    "                          for elem in sim_table[i]] for i in range(num_players)],\n",
    "            'sim_street_idxs': sim_street_idxs.detach(),\n",
    "            'sim_table_position_idxs': sim_table_position_idxs.detach(),\n",
    "            'sim_action_idxs': sim_action_idxs.detach(),\n",
    "            'sim_pot_size_sequence': sim_pot_size_sequence.detach(),\n",
    "            'sim_active_players': sim_active_players.detach(),\n",
    "            'sim_stack_size': sim_stack_size.detach(),\n",
    "        })\n",
    "        all_rewards[len(all_hand_inputs) - 1] = {i: rewards[i] for i in range(num_players)}\n",
    "\n",
    "        for i in range(num_players):\n",
    "            winnings[i].append(winnings[i][-1] + rewards[i].item())\n",
    "\n",
    "    # --- compute advantages across rollouts (no graphs needed) ---\n",
    "    advantages = {}\n",
    "    for player_idx in range(num_players):\n",
    "        player_rewards = torch.stack([all_rewards[h][player_idx].float() for h in range(num_rollouts)])\n",
    "        mean_reward = player_rewards.mean()\n",
    "        std_reward = player_rewards.std() + 1e-8\n",
    "        advantages[player_idx] = (player_rewards - mean_reward) / std_reward  # shape (num_rollouts,)\n",
    "\n",
    "    # --- update one hand at a time ---\n",
    "    for hand_idx, hand_inputs in enumerate(all_hand_inputs):\n",
    "        for player_idx in range(num_players):\n",
    "            log_probs = compute_log_probs(\n",
    "                player_idx,\n",
    "                hand_inputs['player_action_batch_indices'],\n",
    "                hand_inputs['player_masks'],\n",
    "                hand_inputs['sim_table'],\n",
    "                hand_inputs['sim_street_idxs'],\n",
    "                hand_inputs['sim_table_position_idxs'],\n",
    "                hand_inputs['sim_action_idxs'],\n",
    "                hand_inputs['sim_pot_size_sequence'],\n",
    "                hand_inputs['sim_active_players'],\n",
    "                hand_inputs['sim_stack_size'],\n",
    "            )\n",
    "            if log_probs is None:\n",
    "                continue\n",
    "\n",
    "            entropy = -(log_probs * log_probs.exp()).sum(dim=-1).mean()\n",
    "            loss = -(log_probs * advantages[player_idx][hand_idx]).mean() - entropy_coef * entropy\n",
    "            loss.backward()\n",
    "            optimizers[player_idx].step()\n",
    "            optimizers[player_idx].zero_grad()\n",
    "            losses[player_idx].append(loss.item())\n",
    "\n",
    "        torch.cuda.empty_cache()  # free graph after each hand\n",
    "\n",
    "    print(f\"Step {outer_step} | winnings: {winnings}\")\n",
    "    print_gpu_memory(\"Finished up one gradient step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eed88c1b-fffd-43f3-a0fb-25edabfee1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc72a9bae50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([elem/2 for elem in winnings[0]])\n",
    "plt.plot([elem/2 for elem in winnings[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73a78a6-029c-4930-8674-0ac7d5c77fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Allocated: 32.67 GB\n",
      "  Reserved:  32.82 GB\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db35b0-b5bb-403f-8bb4-6af225969ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
