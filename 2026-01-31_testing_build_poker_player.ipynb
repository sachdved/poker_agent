{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4b12ef-30e1-4597-ae15-9d0e550959e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachdved/miniconda3/envs/local_llm_host/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from ml_modules import *\n",
    "from sequence_modules import *\n",
    "from llm_modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a41b808-029e-423e-83c6-7bc74b8218eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_embedder = StreetPositionalEncoding(\n",
    "    num_streets = 4,\n",
    "    embedding_dim = 256,\n",
    "    max_seq_len = 128,\n",
    "    device = \"cpu\"\n",
    ")\n",
    "\n",
    "table_position_embedder = TablePositionalEncoding(\n",
    "    num_players = 2,\n",
    "    embedding_dim = 256,\n",
    "    max_seq_len = 128,\n",
    "    device = \"cpu\"\n",
    ")\n",
    "\n",
    "action_embedder = ActionEncoding(\n",
    "    #num_actions = 21,\n",
    "    embedding_dim = 256,\n",
    "    max_seq_len = 128,\n",
    "    device = \"cpu\"\n",
    ")\n",
    "\n",
    "pot_size_embedder = PotSizeSequenceEmbedder(\n",
    "    max_seq_len = 128,\n",
    "    pad_value = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358b764b-d4cf-46df-8819-9f2e3c3b3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_idxs = torch.Tensor([\n",
    "    [0, 0, 6, 6, 6, 6, 6, 6],\n",
    "    [0, 0, 0, 6, 6, 6, 6, 6],\n",
    "    [0, 0, 0, 0, 6, 6, 6, 6],\n",
    "    [0, 0, 0, 0, 6, 6, 6, 6],\n",
    "    [0, 0, 0, 0, 6, 6, 6, 6],\n",
    "    [0, 0, 0, 0, 6, 6, 6, 6],\n",
    "    [0, 0, 0, 0, 4, 6, 6, 6], \n",
    "    [0, 0, 0, 0, 4, 0, 0, 6], \n",
    "    [0, 0, 0, 0, 4, 0, 0, 6], \n",
    "    [0, 0, 0, 0, 4, 0, 0, 6], \n",
    "    [0, 0, 0, 0, 4, 0, 0, 6], \n",
    "    \n",
    "])\n",
    "table_position_idxs = torch.Tensor([\n",
    "    [0, 1, 2, 2, 2, 2, 2, 2],\n",
    "    [0, 1, 0, 2, 2, 2, 2, 2],\n",
    "    [0, 1, 0, 1, 2, 2, 2, 2],\n",
    "    [0, 1, 0, 1, 2, 2, 2, 2],\n",
    "    [0, 1, 0, 1, 2, 2, 2, 2],\n",
    "    [0, 1, 0, 1, 2, 2, 2, 2],\n",
    "    [0, 1, 0, 1, 2, 2, 2, 2],\n",
    "    [0, 1, 0, 1, 2, 0, 1, 2],\n",
    "    [0, 1, 0, 1, 2, 0, 1, 2],\n",
    "    [0, 1, 0, 1, 2, 0, 1, 2],\n",
    "    [0, 1, 0, 1, 2, 0, 1, 2],\n",
    "\n",
    "])\n",
    "action_idxs = torch.Tensor([\n",
    "    [0, 1, 21, 21, 21, 21, 21, 21],\n",
    "    [0, 1, 4, 21, 21, 21, 21, 21],\n",
    "    [0, 1, 5, 4, 21, 21, 21, 21],\n",
    "    [0, 1, 4, 3, 21, 21, 21, 21],\n",
    "    [0, 1, 5, 6, 21, 21, 21, 21],\n",
    "    [0, 1, 5, 2, 21, 21, 21, 21],\n",
    "    [0, 1, 5, 4, 19, 21, 21, 21],\n",
    "    [0, 1, 5, 4, 19, 3, 3, 21],\n",
    "    [0, 1, 5, 4, 19, 5, 2, 21],\n",
    "    [0, 1, 5, 4, 19, 5, 4, 21],\n",
    "    [0, 1, 5, 4, 19, 3, 5, 21],\n",
    "])\n",
    "pot_size_sequence = torch.Tensor([\n",
    "    [1, 3, -1, -1, -1, -1, -1, -1],\n",
    "    [1, 3, 5, -1, -1, -1, -1, -1],\n",
    "    [1, 3, 7, 8, -1, -1, -1, -1],\n",
    "    [1, 3, 5, 5, -1, -1, -1, -1],\n",
    "    [1, 3, 7, 15, -1, -1, -1, -1],\n",
    "    [1, 3, 7, 7, -1, -1, -1, -1],\n",
    "    [1, 3, 7, 8, 8, -1, -1, -1],\n",
    "    [1, 3, 7, 8, 8, 8, 8, -1],\n",
    "    [1, 3, 7, 8, 8, 10, 10, -1],\n",
    "    [1, 3, 7, 8, 8, 10, 12, -1],\n",
    "    [1, 3, 7, 8, 8, 8, 10, -1],\n",
    "])\n",
    "active_players = torch.Tensor([\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [1, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e7b5c9-45f8-48cc-be7c-6efd6775bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_pot_size_sequence = pot_size_embedder(pot_size_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86be1bc7-e94c-42cc-9f1e-5b2f28480377",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_idxs_out, street_embs = street_embedder(street_idxs)\n",
    "street_embedding = {\n",
    "    'street_idxs': street_idxs_out,\n",
    "    'street_embedding': street_embs,\n",
    "}\n",
    "\n",
    "table_pos_idxs_out, table_pos_embs = table_position_embedder(table_position_idxs)\n",
    "table_position_embedding = {\n",
    "    'table_position_idxs': table_pos_idxs_out,\n",
    "    'table_position_embedding': table_pos_embs,\n",
    "}\n",
    "\n",
    "action_idxs_out, action_embs = action_embedder(action_idxs)\n",
    "action_embedding = {\n",
    "    'action_idxs': action_idxs_out,\n",
    "    'action_embedding': action_embs,\n",
    "}\n",
    "\n",
    "model_inputs = street_embedding | table_position_embedding | action_embedding | {'pot_size_sequence' : padded_pot_size_sequence.unsqueeze(2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb7866c-82ee-4069-a766-67b50b48783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poker_sequence_embedder = PokerSequenceEmbedder(\n",
    "    street_input_dimension = 256,\n",
    "    table_position_input_dimension = 256,\n",
    "    action_input_dimension = 256,\n",
    "    latent_dimensions = [256, 512, 1024, 2048],\n",
    "    device = 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05ed5e6c-32cc-4412-ba39-7e9a013f2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs['attention_mask'] = (model_inputs['pot_size_sequence'] != -1).squeeze(-1).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2945be-9357-40f4-8109-a89d0cf582ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb  5 21:26:30 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.119.02             Driver Version: 580.119.02     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5090        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   24C    P1             35W /  450W |     813MiB /  32607MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1947      G   /usr/bin/kwin_wayland                    13MiB |\n",
      "|    0   N/A  N/A            1958      G   /usr/bin/sddm-greeter-qt6               115MiB |\n",
      "|    0   N/A  N/A            1991      G   /usr/bin/maliit-keyboard                 72MiB |\n",
      "|    0   N/A  N/A           30433      C   ...local_llm_host/bin/python3.11        500MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26b36da-84b5-42b7-ab21-0775be11adbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Initial state\n",
      "  Allocated: 0.00 GB\n",
      "  Reserved:  0.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.31it/s]\n",
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. After loading model\n",
      "  Allocated: 3.44 GB\n",
      "  Reserved:  4.09 GB\n",
      "\n",
      "3. After registering hook\n",
      "  Allocated: 3.44 GB\n",
      "  Reserved:  4.09 GB\n",
      "\n",
      "4. After running one pass\n",
      "  Allocated: 8.85 GB\n",
      "  Reserved:  9.05 GB\n",
      "\n",
      "5. After handle.remove()\n",
      "  Allocated: 8.85 GB\n",
      "  Reserved:  9.05 GB\n",
      "\n",
      "6. After del activation\n",
      "  Allocated: 8.85 GB\n",
      "  Reserved:  9.05 GB\n",
      "\n",
      "7. After del tokenizer\n",
      "  Allocated: 8.85 GB\n",
      "  Reserved:  9.05 GB\n",
      "\n",
      "8. After del model\n",
      "  Allocated: 8.85 GB\n",
      "  Reserved:  9.05 GB\n",
      "\n",
      "9. After del outputs\n",
      "  Allocated: 0.01 GB\n",
      "  Reserved:  9.05 GB\n",
      "\n",
      "10. After gc.collect()\n",
      "  Allocated: 0.01 GB\n",
      "  Reserved:  9.05 GB\n",
      "\n",
      "11. After empty_cache()\n",
      "  Allocated: 0.01 GB\n",
      "  Reserved:  0.02 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def print_gpu_memory(label=\"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        print(f\"{label}\")\n",
    "        print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  Reserved:  {reserved:.2f} GB\")\n",
    "        print()\n",
    "\n",
    "# Run through your code with diagnostics\n",
    "print_gpu_memory(\"1. Initial state\")\n",
    "model_name = \"./models/qwen3-1point7b/\"\n",
    "\n",
    "\n",
    "tokenizer, model = load_model(model_name)\n",
    "\n",
    "model\n",
    "\n",
    "print_gpu_memory(\"2. After loading model\")\n",
    "\n",
    "activation = None\n",
    "def hook(_, __, output):\n",
    "    global activation\n",
    "    activation = output\n",
    "\n",
    "handle = model.model.layers[27].post_attention_layernorm.register_forward_hook(hook)\n",
    "print_gpu_memory(\"3. After registering hook\")\n",
    "\n",
    "inputs_embeds = poker_sequence_embedder(model_inputs).to(device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "outputs = model(inputs_embeds = inputs_embeds, attention_mask = model_inputs['attention_mask'])\n",
    "\n",
    "# Did you actually RUN the model?\n",
    "# If yes, that creates activations\n",
    "# If no, the hook never fires\n",
    "\n",
    "print_gpu_memory(\"4. After running one pass\")\n",
    "\n",
    "\n",
    "handle.remove()\n",
    "print_gpu_memory(\"5. After handle.remove()\")\n",
    "\n",
    "del activation\n",
    "print_gpu_memory(\"6. After del activation\")\n",
    "\n",
    "del tokenizer\n",
    "print_gpu_memory(\"7. After del tokenizer\")\n",
    "\n",
    "del model\n",
    "print_gpu_memory(\"8. After del model\")\n",
    "\n",
    "del outputs\n",
    "print_gpu_memory(\"9. After del outputs\")\n",
    "\n",
    "gc.collect()\n",
    "print_gpu_memory(\"10. After gc.collect()\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print_gpu_memory(\"11. After empty_cache()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d44ca5-55b1-4557-a098-a9e6523631e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Initial state\n",
      "  Allocated: 0.01 GB\n",
      "  Reserved:  0.02 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  5.49it/s]\n",
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. After loading model\n",
      "  Allocated: 3.46 GB\n",
      "  Reserved:  4.10 GB\n",
      "\n",
      "3. After registering hook\n",
      "  Allocated: 3.46 GB\n",
      "  Reserved:  4.10 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def print_gpu_memory(label=\"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        print(f\"{label}\")\n",
    "        print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  Reserved:  {reserved:.2f} GB\")\n",
    "        print()\n",
    "\n",
    "# Run through your code with diagnostics\n",
    "print_gpu_memory(\"1. Initial state\")\n",
    "model_name = \"./models/qwen3-1point7b/\"\n",
    "\n",
    "\n",
    "tokenizer, model = load_model(model_name)\n",
    "\n",
    "model\n",
    "\n",
    "print_gpu_memory(\"2. After loading model\")\n",
    "\n",
    "activation = None\n",
    "def hook(_, __, output):\n",
    "    global activation\n",
    "    activation = output\n",
    "\n",
    "handle = model.model.layers[27].post_attention_layernorm.register_forward_hook(hook)\n",
    "print_gpu_memory(\"3. After registering hook\")\n",
    "\n",
    "inputs_embeds = poker_sequence_embedder(model_inputs).to(device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "outputs = model(inputs_embeds = inputs_embeds, attention_mask = model_inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92b1160a-384e-4529-aa07-1fb52a30ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. After registering hook\n",
      "  Allocated: 13.55 GB\n",
      "  Reserved:  14.65 GB\n",
      "\n",
      "11. After empty_cache()\n",
      "  Allocated: 18.26 GB\n",
      "  Reserved:  19.56 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory(\"3. After registering hook\")\n",
    "\n",
    "inputs_embeds = poker_sequence_embedder(model_inputs).to(device=\"cuda\", dtype=torch.bfloat16)\n",
    "\n",
    "outputs = model(inputs_embeds = inputs_embeds, attention_mask = model_inputs['attention_mask'].to(dtype=torch.int))\n",
    "\n",
    "print_gpu_memory(\"11. After empty_cache()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "312cd46d-7109-4d6c-acf4-bf23d406e8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3301, -4.8750, -0.4395,  ..., -0.2412,  0.7422, -1.0547],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a87dcca1-24d4-458e-9aa4-bf015284fbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1, 21,  ..., 21, 21, 21],\n",
       "        [ 0,  1,  4,  ..., 21, 21, 21],\n",
       "        [ 0,  1,  5,  ..., 21, 21, 21],\n",
       "        ...,\n",
       "        [ 0,  1,  5,  ..., 21, 21, 21],\n",
       "        [ 0,  1,  5,  ..., 21, 21, 21],\n",
       "        [ 0,  1,  5,  ..., 21, 21, 21]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['action_idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0eabaa7-6d5f-42a3-8517-dd3e6b676058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d9ff623-e46c-43df-9666-26d8ceaf9b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "        [-0.2393, -3.2812, -0.0923,  ..., -1.0859,  2.1719, -1.3750],\n",
       "        [ 0.5859, -3.2500, -0.0532,  ..., -2.1406,  1.6484, -1.0234],\n",
       "        ...,\n",
       "        [ 1.0781, -2.7812,  0.0723,  ..., -2.3594,  0.6836, -0.7383],\n",
       "        [ 1.3438, -2.8750, -0.5234,  ..., -1.7891,  0.8516,  0.2217],\n",
       "        [ 1.6641, -2.9844, -0.8633,  ..., -1.7031,  1.0469,  0.0581]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation[torch.arange(11), model_inputs['attention_mask'].sum(dim=1)-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bf1acb0-d0f6-48b8-a837-9b3c6938d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.3438, -3.6406, -1.5703,  ...,  2.3438,  0.9375, -2.9844],\n",
       "         [-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "         [-0.0938, -4.3438, -0.4453,  ..., -0.7461,  1.0938, -1.1562],\n",
       "         ...,\n",
       "         [ 0.3613, -4.8125, -0.5898,  ..., -0.0058,  1.1719, -0.5430],\n",
       "         [ 0.3848, -4.6250, -0.7500,  ...,  0.0688,  1.2422, -0.5078],\n",
       "         [ 0.4082, -4.5000, -0.7344,  ..., -0.2129,  1.2109, -0.4824]],\n",
       "\n",
       "        [[ 3.3438, -3.6406, -1.5703,  ...,  2.3438,  0.9375, -2.9844],\n",
       "         [-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "         [-0.2393, -3.2812, -0.0923,  ..., -1.0859,  2.1719, -1.3750],\n",
       "         ...,\n",
       "         [-0.0703, -4.1875, -0.7031,  ..., -0.1641,  1.5859, -0.3633],\n",
       "         [-0.0253, -4.0625, -0.9062,  ..., -0.0459,  1.5469, -0.4590],\n",
       "         [ 0.1592, -3.8750, -1.0078,  ..., -0.4453,  1.5703, -0.4668]],\n",
       "\n",
       "        [[ 3.3438, -3.6406, -1.5703,  ...,  2.3438,  0.9375, -2.9844],\n",
       "         [-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "         [ 0.6211, -3.4375, -0.1367,  ..., -2.1250,  1.5312, -1.2109],\n",
       "         ...,\n",
       "         [ 0.7344, -3.5938, -0.6250,  ..., -1.3203,  1.4688,  0.5859],\n",
       "         [ 0.5117, -3.4844, -0.8906,  ..., -0.9648,  1.5703,  0.4961],\n",
       "         [ 0.7188, -3.4219, -1.0078,  ..., -1.2656,  1.4375,  0.4648]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.3438, -3.6406, -1.5703,  ...,  2.3438,  0.9375, -2.9844],\n",
       "         [-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "         [ 0.6211, -3.4375, -0.1367,  ..., -2.1250,  1.5312, -1.2109],\n",
       "         ...,\n",
       "         [ 1.2188, -3.1562, -0.8359,  ..., -1.7891,  0.8242,  1.8984],\n",
       "         [ 0.9492, -3.0469, -0.9492,  ..., -1.6250,  0.9883,  1.7500],\n",
       "         [ 0.7109, -2.9531, -1.0000,  ..., -1.6328,  1.2031,  1.6797]],\n",
       "\n",
       "        [[ 3.3438, -3.6406, -1.5703,  ...,  2.3438,  0.9375, -2.9844],\n",
       "         [-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "         [ 0.6211, -3.4375, -0.1367,  ..., -2.1250,  1.5312, -1.2109],\n",
       "         ...,\n",
       "         [ 1.4531, -3.0156, -1.1797,  ..., -1.4766,  0.6641,  2.1250],\n",
       "         [ 1.2578, -3.0156, -1.3203,  ..., -1.4453,  0.7656,  2.0625],\n",
       "         [ 1.1641, -2.9219, -1.3594,  ..., -1.6250,  0.9141,  1.9453]],\n",
       "\n",
       "        [[ 3.3438, -3.6406, -1.5703,  ...,  2.3438,  0.9375, -2.9844],\n",
       "         [-0.1543, -3.5781, -0.5195,  ..., -1.0234,  2.2500, -1.4844],\n",
       "         [ 0.6211, -3.4375, -0.1367,  ..., -2.1250,  1.5312, -1.2109],\n",
       "         ...,\n",
       "         [ 1.6172, -3.2344, -0.9453,  ..., -1.4297,  1.1875,  1.9766],\n",
       "         [ 1.4766, -3.3125, -1.2266,  ..., -1.2500,  1.1484,  1.8828],\n",
       "         [ 1.3359, -3.1875, -1.3359,  ..., -1.4297,  1.1562,  1.6953]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f90fdbc9-8b3c-421b-adde-f3e9c569e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_modules import *\n",
    "\n",
    "cards = Cards()\n",
    "\n",
    "deck_order = torch.randperm(52)\n",
    "card_embeddings = cards(deck_order%13, deck_order//13)\n",
    "unexposed_card = cards(torch.Tensor([13]).to(dtype = torch.long), torch.Tensor([4]).to(dtype = torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bc6c48c-f580-42ad-a599-cd9cce28e244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 2048])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "969215b7-e5af-4c73-856c-5b30db548a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2048])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unexposed_card.tile([3,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e475ec8c-9935-4173-b6c0-5538b8d2ab21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 2048])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e28be68-d6a8-45cb-9faa-102a5a86e4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unexposed_card.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b5ce6ec-6833-458b-8dc0-d9dc171c3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb = Player(hole_cards = card_embeddings[:2], position = 0, folded_or_not = 0)\n",
    "bb = Player(hole_cards = card_embeddings[2:4], position = 1, folded_or_not = 0)\n",
    "\n",
    "board = Board(board_cards = unexposed_card.tile([3,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aeec271a-b828-4176-b29a-ab819c359bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [sb, bb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1583b0d6-fa01-42cd-9d11-2d6e1307052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_players = torch.Tensor([elem.folded_or_not for elem in players]).to(dtype = torch.bfloat16)\n",
    "stack_sizes = torch.Tensor([elem.stack_size for elem in players]).to(dtype = torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8e47e33-6d53-42bb-9ffb-d1bba9e13c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2048])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([sb.hole_cards, board.board_cards], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "982e5d3f-8d23-491c-903c-9422438098a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_order = torch.randperm(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d99f91fb-a047-490b-916e-c76d06ba8c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((deck_order//13)==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66d002eb-eb80-4c47-84b6-f86ca1aafcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((deck_order%13)==12).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6580bcc9-6b57-4d8c-a34c-713ba0683de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs['llm_state'] = activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9b65b54-955a-48d7-a628-569a9b8af0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_players = torch.concat([active_players, stack_sizes], axis=0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65e9b9a1-c1de-4994-b63d-58d124fbfe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_players.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bace7ae-37eb-43aa-8e13-8526ed99e1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 128, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['pot_size_sequence'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c309b70c-4199-4b4d-8e1c-51399facfeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.],\n",
       "        [ 5.],\n",
       "        [ 8.],\n",
       "        [ 5.],\n",
       "        [15.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 8.],\n",
       "        [10.],\n",
       "        [12.],\n",
       "        [10.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['pot_size_sequence'].max(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06511184-fb0a-4deb-807a-8787ea574cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs['card_state'] = torch.concat([sb.hole_cards, board.board_cards], axis=0).tile([11,1,1])\n",
    "model_inputs['active_players_state'] = active_players.tile([11,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2118bad9-f23f-47c7-86cc-732e104b801f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'street_idxs': tensor([[0, 0, 6,  ..., 6, 6, 6],\n",
       "         [0, 0, 0,  ..., 6, 6, 6],\n",
       "         [0, 0, 0,  ..., 6, 6, 6],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 6, 6, 6],\n",
       "         [0, 0, 0,  ..., 6, 6, 6],\n",
       "         [0, 0, 0,  ..., 6, 6, 6]]),\n",
       " 'street_embedding': tensor([[[ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          ...,\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339]],\n",
       " \n",
       "         [[ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          ...,\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339]],\n",
       " \n",
       "         [[ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          ...,\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          ...,\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339]],\n",
       " \n",
       "         [[ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          ...,\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339]],\n",
       " \n",
       "         [[ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          [ 0.9827, -0.5144,  1.3626,  ...,  0.8392, -0.2706, -0.8136],\n",
       "          ...,\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339],\n",
       "          [ 0.2170,  1.7004, -0.0420,  ...,  0.5870, -0.6570, -0.0339]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " 'table_position_idxs': tensor([[0, 1, 2,  ..., 3, 3, 3],\n",
       "         [0, 1, 0,  ..., 3, 3, 3],\n",
       "         [0, 1, 0,  ..., 3, 3, 3],\n",
       "         ...,\n",
       "         [0, 1, 0,  ..., 3, 3, 3],\n",
       "         [0, 1, 0,  ..., 3, 3, 3],\n",
       "         [0, 1, 0,  ..., 3, 3, 3]]),\n",
       " 'table_position_embedding': tensor([[[ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          [-1.7633, -0.6033,  0.7817,  ..., -1.0647,  0.2001, -0.4571],\n",
       "          [ 0.5201,  1.3164, -1.1983,  ..., -0.2751, -0.2833,  0.3297],\n",
       "          ...,\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661]],\n",
       " \n",
       "         [[ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          [-1.7633, -0.6033,  0.7817,  ..., -1.0647,  0.2001, -0.4571],\n",
       "          [ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          ...,\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661]],\n",
       " \n",
       "         [[ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          [-1.7633, -0.6033,  0.7817,  ..., -1.0647,  0.2001, -0.4571],\n",
       "          [ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          ...,\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          [-1.7633, -0.6033,  0.7817,  ..., -1.0647,  0.2001, -0.4571],\n",
       "          [ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          ...,\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661]],\n",
       " \n",
       "         [[ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          [-1.7633, -0.6033,  0.7817,  ..., -1.0647,  0.2001, -0.4571],\n",
       "          [ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          ...,\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661]],\n",
       " \n",
       "         [[ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          [-1.7633, -0.6033,  0.7817,  ..., -1.0647,  0.2001, -0.4571],\n",
       "          [ 2.1593, -0.8655,  1.1956,  ...,  0.3337, -1.7137, -0.3412],\n",
       "          ...,\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661],\n",
       "          [-0.2401, -0.0865,  1.9624,  ...,  0.3250,  0.7184,  1.4661]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " 'action_idxs': tensor([[ 0,  1, 21,  ..., 21, 21, 21],\n",
       "         [ 0,  1,  4,  ..., 21, 21, 21],\n",
       "         [ 0,  1,  5,  ..., 21, 21, 21],\n",
       "         ...,\n",
       "         [ 0,  1,  5,  ..., 21, 21, 21],\n",
       "         [ 0,  1,  5,  ..., 21, 21, 21],\n",
       "         [ 0,  1,  5,  ..., 21, 21, 21]]),\n",
       " 'action_embedding': tensor([[[-1.1058, -1.3396,  1.0998,  ...,  0.5699,  0.7972, -0.1546],\n",
       "          [ 0.0553,  1.1860, -0.5063,  ..., -1.6544, -0.4746, -0.0260],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          ...,\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248]],\n",
       " \n",
       "         [[-1.1058, -1.3396,  1.0998,  ...,  0.5699,  0.7972, -0.1546],\n",
       "          [ 0.0553,  1.1860, -0.5063,  ..., -1.6544, -0.4746, -0.0260],\n",
       "          [ 0.1921,  0.7779, -1.2541,  ..., -0.3362,  0.9462, -1.9358],\n",
       "          ...,\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248]],\n",
       " \n",
       "         [[-1.1058, -1.3396,  1.0998,  ...,  0.5699,  0.7972, -0.1546],\n",
       "          [ 0.0553,  1.1860, -0.5063,  ..., -1.6544, -0.4746, -0.0260],\n",
       "          [ 0.7818, -0.6149,  1.5211,  ..., -0.5017, -1.4894, -1.4876],\n",
       "          ...,\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.1058, -1.3396,  1.0998,  ...,  0.5699,  0.7972, -0.1546],\n",
       "          [ 0.0553,  1.1860, -0.5063,  ..., -1.6544, -0.4746, -0.0260],\n",
       "          [ 0.7818, -0.6149,  1.5211,  ..., -0.5017, -1.4894, -1.4876],\n",
       "          ...,\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248]],\n",
       " \n",
       "         [[-1.1058, -1.3396,  1.0998,  ...,  0.5699,  0.7972, -0.1546],\n",
       "          [ 0.0553,  1.1860, -0.5063,  ..., -1.6544, -0.4746, -0.0260],\n",
       "          [ 0.7818, -0.6149,  1.5211,  ..., -0.5017, -1.4894, -1.4876],\n",
       "          ...,\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248]],\n",
       " \n",
       "         [[-1.1058, -1.3396,  1.0998,  ...,  0.5699,  0.7972, -0.1546],\n",
       "          [ 0.0553,  1.1860, -0.5063,  ..., -1.6544, -0.4746, -0.0260],\n",
       "          [ 0.7818, -0.6149,  1.5211,  ..., -0.5017, -1.4894, -1.4876],\n",
       "          ...,\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248],\n",
       "          [ 1.8881, -1.5474, -2.1512,  ..., -1.3698, -0.2771,  0.3248]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " 'pot_size_sequence': tensor([[[ 1.],\n",
       "          [ 3.],\n",
       "          [-1.],\n",
       "          ...,\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[ 1.],\n",
       "          [ 3.],\n",
       "          [ 5.],\n",
       "          ...,\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[ 1.],\n",
       "          [ 3.],\n",
       "          [ 7.],\n",
       "          ...,\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.],\n",
       "          [ 3.],\n",
       "          [ 7.],\n",
       "          ...,\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[ 1.],\n",
       "          [ 3.],\n",
       "          [ 7.],\n",
       "          ...,\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]],\n",
       " \n",
       "         [[ 1.],\n",
       "          [ 3.],\n",
       "          [ 7.],\n",
       "          ...,\n",
       "          [-1.],\n",
       "          [-1.],\n",
       "          [-1.]]]),\n",
       " 'attention_mask': tensor([[ True,  True, False,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]], device='cuda:0'),\n",
       " 'llm_state': tensor([[[ 3.8906, -3.7500, -0.0630,  ...,  2.3594, -2.7812, -2.6875],\n",
       "          [ 5.7812, -2.6250, -0.6523,  ...,  0.8984, -2.8906, -2.0156],\n",
       "          [ 5.5312, -3.0312,  0.5039,  ...,  0.8203, -3.1406, -0.7422],\n",
       "          ...,\n",
       "          [ 5.6562, -2.4219, -1.3359,  ...,  1.2422, -2.8125, -0.5469],\n",
       "          [ 5.6875, -2.7031, -1.1953,  ...,  0.9492, -2.8438, -0.6172],\n",
       "          [ 5.7812, -2.7500, -1.0625,  ...,  0.6914, -2.7500, -0.7578]],\n",
       " \n",
       "         [[ 3.8906, -3.7500, -0.0630,  ...,  2.3594, -2.7812, -2.6875],\n",
       "          [ 5.7812, -2.6250, -0.6523,  ...,  0.8984, -2.8906, -2.0156],\n",
       "          [ 6.5938, -3.9219, -0.0615,  ..., -0.8711, -2.9219, -1.3984],\n",
       "          ...,\n",
       "          [ 6.2188, -2.5000, -0.8203,  ...,  0.7812, -2.7188, -0.3574],\n",
       "          [ 6.3125, -2.7656, -0.8516,  ...,  0.5430, -2.6875, -0.4023],\n",
       "          [ 6.3750, -2.7656, -0.7070,  ...,  0.3770, -2.5312, -0.3047]],\n",
       " \n",
       "         [[ 3.8906, -3.7500, -0.0630,  ...,  2.3594, -2.7812, -2.6875],\n",
       "          [ 5.7812, -2.6250, -0.6523,  ...,  0.8984, -2.8906, -2.0156],\n",
       "          [ 5.9688, -3.2812,  0.7461,  ..., -0.0537, -3.1406, -1.4531],\n",
       "          ...,\n",
       "          [ 5.6875, -2.2969, -0.8047,  ...,  0.7344, -2.2188, -0.4062],\n",
       "          [ 5.7812, -2.5625, -0.8047,  ...,  0.6094, -2.0625, -0.2773],\n",
       "          [ 5.8125, -2.4062, -0.5977,  ...,  0.5820, -1.8203, -0.0123]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 3.8906, -3.7500, -0.0630,  ...,  2.3594, -2.7812, -2.6875],\n",
       "          [ 5.7812, -2.6250, -0.6523,  ...,  0.8984, -2.8906, -2.0156],\n",
       "          [ 5.9688, -3.2812,  0.7461,  ..., -0.0537, -3.1406, -1.4531],\n",
       "          ...,\n",
       "          [ 5.2812, -2.0156, -1.1016,  ...,  0.5781, -2.6562, -0.5469],\n",
       "          [ 5.3125, -2.4219, -1.0781,  ...,  0.3379, -2.7500, -0.8125],\n",
       "          [ 5.3438, -2.4844, -1.0391,  ...,  0.2129, -2.5469, -0.6094]],\n",
       " \n",
       "         [[ 3.8906, -3.7500, -0.0630,  ...,  2.3594, -2.7812, -2.6875],\n",
       "          [ 5.7812, -2.6250, -0.6523,  ...,  0.8984, -2.8906, -2.0156],\n",
       "          [ 5.9688, -3.2812,  0.7461,  ..., -0.0537, -3.1406, -1.4531],\n",
       "          ...,\n",
       "          [ 5.2188, -1.9453, -1.2969,  ...,  0.8320, -2.2500, -0.1108],\n",
       "          [ 5.2500, -2.3125, -1.3906,  ...,  0.5742, -2.2969, -0.3945],\n",
       "          [ 5.2188, -2.5000, -1.3125,  ...,  0.4414, -2.0938, -0.2139]],\n",
       " \n",
       "         [[ 3.8906, -3.7500, -0.0630,  ...,  2.3594, -2.7812, -2.6875],\n",
       "          [ 5.7812, -2.6250, -0.6523,  ...,  0.8984, -2.8906, -2.0156],\n",
       "          [ 5.9688, -3.2812,  0.7461,  ..., -0.0537, -3.1406, -1.4531],\n",
       "          ...,\n",
       "          [ 5.2500, -1.9766, -1.1953,  ...,  0.5430, -2.2969, -0.4512],\n",
       "          [ 5.2812, -2.2344, -1.1719,  ...,  0.2676, -2.3438, -0.6836],\n",
       "          [ 5.3125, -2.3438, -1.2422,  ...,  0.1758, -2.1875, -0.4727]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<MulBackward0>),\n",
       " 'card_state': tensor([[[-1.2189,  0.1790, -0.9439,  ...,  1.3507,  0.1983,  0.4280],\n",
       "          [ 0.1077,  1.4811, -0.8857,  ...,  0.9440,  1.7754,  0.5972],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326]],\n",
       " \n",
       "         [[-1.2189,  0.1790, -0.9439,  ...,  1.3507,  0.1983,  0.4280],\n",
       "          [ 0.1077,  1.4811, -0.8857,  ...,  0.9440,  1.7754,  0.5972],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326]],\n",
       " \n",
       "         [[-1.2189,  0.1790, -0.9439,  ...,  1.3507,  0.1983,  0.4280],\n",
       "          [ 0.1077,  1.4811, -0.8857,  ...,  0.9440,  1.7754,  0.5972],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.2189,  0.1790, -0.9439,  ...,  1.3507,  0.1983,  0.4280],\n",
       "          [ 0.1077,  1.4811, -0.8857,  ...,  0.9440,  1.7754,  0.5972],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326]],\n",
       " \n",
       "         [[-1.2189,  0.1790, -0.9439,  ...,  1.3507,  0.1983,  0.4280],\n",
       "          [ 0.1077,  1.4811, -0.8857,  ...,  0.9440,  1.7754,  0.5972],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326]],\n",
       " \n",
       "         [[-1.2189,  0.1790, -0.9439,  ...,  1.3507,  0.1983,  0.4280],\n",
       "          [ 0.1077,  1.4811, -0.8857,  ...,  0.9440,  1.7754,  0.5972],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326],\n",
       "          [-0.6687, -0.2136,  0.2662,  ..., -0.8905, -0.7907,  0.3326]]],\n",
       "        grad_fn=<RepeatBackward0>),\n",
       " 'active_players_state': tensor([[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]], dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "da23da73-e09f-48db-9fe0-08e16d0c7367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 128, 2048])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b855f0-96ab-4645-bc14-e840c11aa03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs[''] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86cd289-687e-4a81-9ff0-295d1c0b03d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyMaker(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Given the embedding from an LLM of the sequence\n",
    "    of the poker hand, information about the what cards are available,\n",
    "    information about the stack sizes and information about\n",
    "    who is active or inactive in the hand, returns two probability distributions\n",
    "    over the possible actions, and the mask over the action space: one is a best response\n",
    "    policy (trained by RL) and the other is a learned average policy (trained by SL).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_players : int,\n",
    "        poker_sequence_embedder : torch.nn.Module,\n",
    "        card_latent_dims: typing.List[int],\n",
    "        active_players_latent_dims: typing.List[int],\n",
    "        final_decision_latent_dims: typing.List[int],\n",
    "        device: str = 'cpu'\n",
    "    ):\n",
    "        \n",
    "        self.num_players = num_players\n",
    "        self.active_players_latent_dims = active_players_latent_dims\n",
    "        self.card_latent_dims = card_latent_dims\n",
    "        self.final_decision_latent_dims = final_decision_latent_dims\n",
    "        \n",
    "        self.poker_sequence_embedder = poker_sequence_embedder\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        def make_mlp(input_dim: int, latent_dimensions : typing.List[int]) -> torch.nn.Sequential:\n",
    "            dims = [input_dim] + latent_dimensions\n",
    "            layers = []\n",
    "            for i in range(len(dims) - 1):\n",
    "                layers.append(torch.nn.Linear(dims[i], dims[i + 1]))\n",
    "                layers.append(torch.nn.LayerNorm(dims[i + 1]))\n",
    "                if i < len(dims) - 2:  # no ReLU on final layer\n",
    "                    layers.append(torch.nn.ReLU())\n",
    "            return torch.nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "        self.active_players_mlp = make_mlp(2 * self.num_players, self.active_players_latent_dims) #active or not and stack size\n",
    "        self.cards_mlp = make_mlp(5, self.card_latent_dims) # 5 cards in poker\n",
    "        self.final_decision_mlp = make_mlp(2048*3, self.final_decision_latent_dims)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        model_inputs,\n",
    "        ,\n",
    "        board\n",
    "    ) -> torch.Tensor:\n",
    "        llm_state = model_inputs['llm_state']\n",
    "        active_players = model_inputs['active_players_state']\n",
    "        card_state = model_inputs['']\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a07f5010-a039-4f08-8056-f90448fd7c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['street_idxs', 'street_embedding', 'table_position_idxs', 'table_position_embedding', 'action_idxs', 'action_embedding', 'pot_size_sequence', 'attention_mask', 'llm_state', 'card_state', 'active_players_state'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc4561-b6b5-4098-a12d-d89c92406847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
