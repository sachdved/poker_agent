{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4fb7ee-343c-4367-9066-e47eaa8befb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sachdved/miniconda3/envs/local_llm_host/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72944cb-90c4-4bb1-bcc2-04029c34c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 25 20:10:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.119.02             Driver Version: 580.119.02     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5090        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   25C    P8             23W /  450W |     136MiB /  32607MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2504      G   /usr/bin/kwin_wayland                    36MiB |\n",
      "|    0   N/A  N/A            2613      G   /usr/bin/Xwayland                         8MiB |\n",
      "|    0   N/A  N/A            2683      G   /usr/bin/plasmashell                      6MiB |\n",
      "|    0   N/A  N/A            4189      G   /usr/libexec/kscreenlocker_greet          6MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e981246f-69b4-4938-892d-1df40c6f0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"models/commandr35b4bits/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b22c8f9-0f24-484d-af9d-7a9a08ab546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d868465d-52f2-4c54-a4b8-0f7334715690",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ff10b0-8214-42e6-a2cb-677d9b48e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/home/sachdved/miniconda3/envs/local_llm_host/lib/python3.11/site-packages/transformers/quantizers/auto.py:239: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.14it/s]\n",
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = \"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24d82d87-f34b-48b4-a8fc-86ae22c1e673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 25 20:10:24 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.119.02             Driver Version: 580.119.02     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5090        Off |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   27C    P1             69W /  450W |   22424MiB /  32607MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2504      G   /usr/bin/kwin_wayland                    36MiB |\n",
      "|    0   N/A  N/A            2613      G   /usr/bin/Xwayland                         8MiB |\n",
      "|    0   N/A  N/A            2683      G   /usr/bin/plasmashell                      6MiB |\n",
      "|    0   N/A  N/A            4189      G   /usr/libexec/kscreenlocker_greet          6MiB |\n",
      "|    0   N/A  N/A            4275      C   ...local_llm_host/bin/python3.11      22280MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26f553a2-5a98-4940-8275-da06d4d2704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Help me write some code to scrape Bloomberg RSS feeds for news headlines\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26157e4c-975e-4b35-a817-75b43bdb683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=1024,\n",
    "    do_sample = False,\n",
    "    temperature = 0.5,\n",
    "    top_p = 0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe17c20a-f38f-4f41-8570-4a0826d30a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    5, 29743,  2307,  ...,  2063,  8565,  2075]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f55f0a0f-d3d0-4b73-a89b-e153d97cf75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.decode(outputs[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13a103af-1a0c-49d6-89a3-aedab3d721a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Help me write some code to scrape Bloomberg RSS feeds for news headlines and store them in a database.\\nBudget $30-250 USD\\nI need a script that will scrape the Bloomberg RSS feeds for news headlines and store them in a database. I will need to be able to specify the RSS feeds I want to scrape. I will also need to be able to specify the database table and fields where the headlines will be stored. I will also need to be able to specify the frequency of the scraping.\\nAwarded to:\\nHello, I can help you with this project. Please check your PM. Thanks.\\n10 freelancers are bidding on average $149 for this job\\nHello, We are interested to work on this project, Please check PM. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.Hi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.Hi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.Hi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this project. Please check your PM for details. Thanks.\\nHi, I have experience in web scraping and can deliver this'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f44b168-15e8-4f1a-91dc-c53eee3b4fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    5,  5284,   228,    26,    25, 30647, 41748,  4311,  5165,    19,\n",
       "          3119,  1914,  1690,  9717,  1777, 38517,  1767,  2063, 10747,    38]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "049e0211-1e01-4be3-a3ad-6fb0bee1575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.model.embed_tokens(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ad3e4c9-9020-409c-a47c-e9d07f638166",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(\n",
    "    inputs['input_ids'],\n",
    "    output_hidden_states=True,\n",
    "    use_cache=False\n",
    ")\n",
    "h0 = out.hidden_states[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f107ec0-91e5-47a4-9dbe-909bd6333ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 256000])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd146ea8-cbf6-4dd2-bba0-8243c0e02612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0009,  0.0021,  0.0007,  ..., -0.0015,  0.0005,  0.0005],\n",
       "          [ 0.0391, -0.1016,  0.0259,  ..., -0.0195,  0.0277,  0.0080],\n",
       "          [ 0.0430,  0.1055, -0.0688,  ...,  0.0396, -0.0066,  0.0322],\n",
       "          ...,\n",
       "          [-0.0217,  0.0398, -0.0566,  ..., -0.0237,  0.0103,  0.0391],\n",
       "          [-0.0850,  0.0378, -0.0255,  ..., -0.0309, -0.0044, -0.0087],\n",
       "          [-0.0466,  0.0288, -0.0354,  ...,  0.0483, -0.0713,  0.0201]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[[ 0.0567,  0.0117, -0.0556,  ..., -0.0530, -0.0673,  0.0592],\n",
       "          [ 0.0775, -0.1414, -0.2910,  ..., -0.0204, -0.0434, -0.0233],\n",
       "          [ 0.0464,  0.0154, -0.0261,  ..., -0.0447, -0.0044,  0.0495],\n",
       "          ...,\n",
       "          [ 0.0124,  0.0089, -0.3462,  ..., -0.0665, -0.0420, -0.0074],\n",
       "          [ 0.0802,  0.0008, -0.1753,  ...,  0.0143, -0.0057,  0.0527],\n",
       "          [-0.0686, -0.0704, -0.1378,  ..., -0.0265, -0.0566,  0.0511]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0621,  0.0776, -0.2301,  ..., -0.2361, -0.0109, -0.0772],\n",
       "          [ 0.0820, -0.1545, -0.2079,  ...,  0.0080,  0.0020,  0.0833],\n",
       "          [ 0.0676, -0.0093, -0.0529,  ..., -0.0516,  0.0051, -0.0021],\n",
       "          ...,\n",
       "          [ 0.0017, -0.0631, -0.4456,  ..., -0.0218,  0.0395, -0.0105],\n",
       "          [ 0.0863, -0.0052, -0.2634,  ...,  0.1921,  0.0811,  0.1420],\n",
       "          [-0.0701, -0.1013, -0.1368,  ..., -0.0422, -0.0674,  0.0435]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0678,  0.0842, -0.2355,  ..., -0.2440, -0.0291, -0.0825],\n",
       "          [ 0.1268, -0.0994, -0.1978,  ..., -0.0233, -0.0372,  0.0964],\n",
       "          [ 0.1117,  0.0255, -0.0570,  ..., -0.0767, -0.0247,  0.0129],\n",
       "          ...,\n",
       "          [-0.0814, -0.1405, -0.3733,  ..., -0.0615,  0.1409, -0.0616],\n",
       "          [ 0.0128, -0.1191, -0.2401,  ...,  0.1400,  0.0347,  0.0865],\n",
       "          [-0.0468, -0.1719, -0.0342,  ..., -0.1082, -0.0462,  0.0370]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0813,  0.0784, -0.2312,  ..., -0.2292, -0.0169, -0.0978],\n",
       "          [ 0.2051, -0.0721, -0.2080,  ...,  0.0103,  0.0346,  0.1349],\n",
       "          [ 0.1658,  0.1537, -0.1331,  ...,  0.0267,  0.0032, -0.0223],\n",
       "          ...,\n",
       "          [ 0.0240,  0.0084, -0.3896,  ...,  0.0028,  0.0593, -0.1372],\n",
       "          [ 0.1005, -0.1646, -0.3591,  ...,  0.2371,  0.0041,  0.0399],\n",
       "          [-0.1321, -0.0953, -0.1187,  ..., -0.1104, -0.1295, -0.0083]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0836,  0.0610, -0.2449,  ..., -0.2220, -0.0319, -0.1185],\n",
       "          [ 0.2340, -0.1584, -0.1904,  ...,  0.0819,  0.1261,  0.1721],\n",
       "          [ 0.2722, -0.0493, -0.2749,  ...,  0.0400, -0.0528,  0.1306],\n",
       "          ...,\n",
       "          [ 0.0964, -0.1127, -0.3787,  ...,  0.0880,  0.1707, -0.1638],\n",
       "          [ 0.1628, -0.1464, -0.3628,  ...,  0.1044, -0.0246,  0.0493],\n",
       "          [-0.0781, -0.2017,  0.0285,  ..., -0.0286, -0.0093,  0.1226]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0846,  0.1101, -0.2456,  ..., -0.2595, -0.0434, -0.1362],\n",
       "          [ 0.1404, -0.2126, -0.1686,  ...,  0.1002,  0.1932,  0.2544],\n",
       "          [ 0.1566,  0.0580, -0.3618,  ...,  0.1309, -0.0491,  0.0781],\n",
       "          ...,\n",
       "          [ 0.1581, -0.1600, -0.5605,  ...,  0.1785,  0.1278, -0.3552],\n",
       "          [ 0.1765, -0.2778, -0.5205,  ...,  0.1304,  0.0481,  0.1506],\n",
       "          [-0.2185, -0.3765, -0.1346,  ..., -0.0428, -0.0296,  0.0981]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.1076,  0.1130, -0.2379,  ..., -0.2225, -0.0235, -0.1376],\n",
       "          [ 0.1252, -0.1586, -0.1006,  ...,  0.0905,  0.3062,  0.3257],\n",
       "          [ 0.3950,  0.2228, -0.3335,  ...,  0.3130,  0.0731,  0.1010],\n",
       "          ...,\n",
       "          [ 0.2455, -0.3450, -0.5776,  ...,  0.2893,  0.0620,  0.0579],\n",
       "          [ 0.1959, -0.3135, -0.6084,  ...,  0.0601, -0.1309,  0.2539],\n",
       "          [-0.2224, -0.4700, -0.2231,  ..., -0.0277,  0.0760,  0.2668]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0897,  0.1687, -0.2820,  ..., -0.2323,  0.0444, -0.0745],\n",
       "          [ 0.1114, -0.1855, -0.1929,  ...,  0.1075,  0.3350,  0.2559],\n",
       "          [ 0.3604,  0.1945, -0.2036,  ...,  0.4204,  0.1934,  0.2607],\n",
       "          ...,\n",
       "          [-0.0620, -0.2290, -0.3916,  ...,  0.1683,  0.1118,  0.3123],\n",
       "          [ 0.3098, -0.2969, -0.1584,  ...,  0.1285,  0.2964,  0.0786],\n",
       "          [-0.3345, -0.3088, -0.3279,  ..., -0.1678,  0.0945,  0.2493]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 1.0822e-01,  1.3843e-01, -2.6074e-01,  ..., -2.1875e-01,\n",
       "            6.2744e-02, -4.0344e-02],\n",
       "          [ 1.0516e-01, -3.6450e-01,  3.6621e-04,  ...,  1.2207e-02,\n",
       "            4.6729e-01,  3.5254e-01],\n",
       "          [ 3.9844e-01,  2.3352e-01, -1.9592e-01,  ...,  4.1504e-01,\n",
       "            2.7271e-01,  2.2742e-01],\n",
       "          ...,\n",
       "          [-1.0132e-01, -1.3635e-01, -4.3262e-01,  ..., -1.4441e-01,\n",
       "            1.3989e-01,  2.6245e-01],\n",
       "          [ 2.0654e-01, -4.3018e-01, -2.8381e-02,  ...,  1.7322e-01,\n",
       "            1.1731e-01,  8.5449e-02],\n",
       "          [-5.8643e-01, -2.6270e-01, -1.6235e-01,  ..., -1.4404e-01,\n",
       "           -1.1029e-01,  1.7114e-01]]], device='cuda:0', dtype=torch.float16,\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.1597,  0.0952, -0.2430,  ..., -0.2610,  0.0732, -0.0655],\n",
       "          [ 0.1727, -0.6196,  0.0027,  ...,  0.1873,  0.6201,  0.3967],\n",
       "          [ 0.4197,  0.4346, -0.5767,  ...,  0.6172,  0.4851,  0.3772],\n",
       "          ...,\n",
       "          [-0.2196,  0.1041, -0.1475,  ...,  0.0061, -0.1893, -0.0183],\n",
       "          [ 0.0788, -0.1891,  0.0634,  ..., -0.1652,  0.4365,  0.2629],\n",
       "          [-0.5996,  0.1455,  0.0184,  ...,  0.0546, -0.0502, -0.0408]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0645, -0.0100, -0.2053,  ..., -0.3157,  0.0644, -0.0276],\n",
       "          [ 0.5107, -0.8711,  0.1501,  ...,  0.0635,  0.7622,  0.8486],\n",
       "          [ 0.2656,  0.2715, -0.6450,  ...,  0.6733,  0.1667,  0.3955],\n",
       "          ...,\n",
       "          [ 0.0825, -0.4634,  0.0433,  ...,  0.0930,  0.2661,  0.0497],\n",
       "          [ 0.2717, -0.0361,  0.0797,  ..., -0.1625,  0.1149,  0.2314],\n",
       "          [-0.4854,  0.4146,  0.2915,  ...,  0.1196,  0.4724, -0.4277]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 3.9062e-02, -2.0276e-01, -2.8857e-01,  ..., -3.0518e-01,\n",
       "            1.9226e-03,  7.4768e-04],\n",
       "          [ 6.6650e-01, -8.7939e-01,  1.9116e-01,  ..., -5.4382e-02,\n",
       "            8.1934e-01,  8.5986e-01],\n",
       "          [ 3.8428e-01,  1.4185e-01, -3.4277e-01,  ...,  7.9248e-01,\n",
       "            2.8198e-01,  2.4670e-01],\n",
       "          ...,\n",
       "          [-1.2939e-01, -3.5645e-01,  4.9658e-01,  ...,  3.1738e-02,\n",
       "           -1.8835e-01, -1.7114e-01],\n",
       "          [ 4.9316e-01, -3.1348e-01,  4.9438e-01,  ..., -1.8921e-01,\n",
       "           -8.4351e-02,  4.5264e-01],\n",
       "          [-6.0986e-01,  7.1777e-02,  5.3223e-01,  ..., -1.4343e-01,\n",
       "            4.2480e-01, -4.5654e-01]]], device='cuda:0', dtype=torch.float16,\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0169, -0.1707,  0.3281,  ..., -0.3503, -0.0168, -0.1147],\n",
       "          [ 0.6816, -0.9478,  0.0890,  ...,  0.0969,  0.7832,  0.8999],\n",
       "          [ 0.1177,  0.2974, -0.7876,  ...,  0.6821,  0.4478,  0.2457],\n",
       "          ...,\n",
       "          [-0.1567, -0.7295,  0.3379,  ..., -0.6152, -0.1277, -0.0532],\n",
       "          [ 0.2786, -0.5342,  0.5303,  ..., -0.1621, -0.0842,  0.8320],\n",
       "          [-0.6636, -0.0993,  0.3550,  ..., -0.3696,  0.3247, -0.2274]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 0.0056, -0.2030,  0.2825,  ..., -0.4253, -0.0622, -0.0488],\n",
       "          [ 0.7383, -1.0605,  0.1160,  ...,  0.0912,  0.7026,  0.9600],\n",
       "          [ 0.3083,  0.3159, -0.4653,  ...,  0.7041,  0.2585,  0.4419],\n",
       "          ...,\n",
       "          [ 0.2240, -0.5791,  0.0771,  ..., -0.7261, -0.0780, -0.3882],\n",
       "          [ 0.3821, -0.7559,  0.4397,  ..., -0.1281, -0.6006,  1.2246],\n",
       "          [-0.4097, -0.4568,  0.1846,  ..., -0.3176, -0.2078, -0.1321]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.0784, -0.1246,  0.2280,  ..., -0.4299, -0.1145, -0.0282],\n",
       "          [ 0.7207, -1.0693,  0.0739,  ...,  0.2185,  0.6196,  1.0283],\n",
       "          [-0.0251,  0.4216, -0.4421,  ...,  0.6597,  0.2932,  0.1038],\n",
       "          ...,\n",
       "          [-0.4048, -0.9307,  0.0118,  ..., -0.3438, -0.0543, -0.0890],\n",
       "          [ 0.3657, -0.8623,  0.2676,  ..., -0.4805, -0.5996,  1.2227],\n",
       "          [-0.4758, -0.8740,  0.0732,  ..., -0.5303, -0.0986,  0.2529]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.0830, -0.1897,  0.2974,  ..., -0.4744, -0.1655, -0.0744],\n",
       "          [ 0.6685, -1.0664,  0.1670,  ...,  0.2793,  0.5869,  0.9014],\n",
       "          [ 0.0343,  0.2842, -0.7554,  ...,  0.9980,  0.2925, -0.2072],\n",
       "          ...,\n",
       "          [-0.3645, -0.4275, -0.0952,  ..., -0.8633, -0.1462,  0.2058],\n",
       "          [ 0.2583, -0.5527, -0.1180,  ..., -0.6260, -0.6895,  1.4902],\n",
       "          [-0.4348, -0.6675, -0.1222,  ..., -1.0000,  0.2925,  0.5488]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.1213, -0.2234,  0.3389,  ..., -0.3765, -0.1024, -0.0790],\n",
       "          [ 0.5410, -1.0732,  0.1543,  ...,  0.3335,  0.6235,  1.0244],\n",
       "          [ 0.3423,  0.0648, -1.0459,  ...,  0.7261,  0.1418, -0.5566],\n",
       "          ...,\n",
       "          [ 0.0034, -0.6006, -0.0992,  ..., -0.4080,  0.3237, -0.1580],\n",
       "          [ 0.4258, -0.3298, -0.6704,  ..., -0.7095, -0.2222,  1.1357],\n",
       "          [-0.1958, -0.6553, -0.2588,  ..., -1.1221,  0.6475, -0.0283]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2325, -0.2864,  0.3733,  ..., -0.3594, -0.2283, -0.0685],\n",
       "          [ 0.5366, -1.0332,  0.0782,  ...,  0.4397,  0.5005,  1.0439],\n",
       "          [ 0.6953, -0.1901, -0.9990,  ...,  0.7734,  0.1132, -0.4641],\n",
       "          ...,\n",
       "          [-0.3044, -0.5967, -0.1625,  ...,  0.0405,  0.4346,  0.2377],\n",
       "          [ 0.3984, -0.4990, -0.4634,  ..., -0.8252, -0.1095,  1.0742],\n",
       "          [-0.1772, -0.6162,  0.0999,  ..., -1.2422,  0.2222,  0.2849]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2681, -0.2729,  0.4094,  ..., -0.3394, -0.3130, -0.0813],\n",
       "          [ 0.4597, -0.8965,  0.0887,  ...,  0.5400,  0.4844,  1.0459],\n",
       "          [ 0.6187, -0.0817, -1.4375,  ...,  0.8926,  0.3833, -0.3081],\n",
       "          ...,\n",
       "          [-0.4441, -0.5615,  0.0277,  ..., -0.0460,  0.3596, -0.1956],\n",
       "          [ 0.7700, -0.5557, -0.0640,  ..., -0.5957,  0.2581,  0.9365],\n",
       "          [-0.4077, -0.5815,  0.0297,  ..., -1.5156,  0.1626, -0.0328]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2883, -0.1962,  0.4004,  ..., -0.3169, -0.2822, -0.1456],\n",
       "          [ 0.4175, -1.1152,  0.1304,  ...,  0.6245,  0.4431,  0.9429],\n",
       "          [ 0.4839,  0.1251, -1.4297,  ...,  1.0059, -0.0798, -0.2703],\n",
       "          ...,\n",
       "          [ 0.1279, -0.4731,  0.1906,  ..., -0.5474,  0.7153,  0.3052],\n",
       "          [ 0.5483,  0.1350,  0.1927,  ..., -1.3184,  0.5430,  0.7686],\n",
       "          [-0.5059, -0.5332,  0.5024,  ..., -2.0586,  0.3679,  0.4268]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.1484, -0.3032,  0.4746,  ..., -0.2377, -0.2253, -0.0485],\n",
       "          [ 0.3625, -1.0342,  0.1927,  ...,  0.6484,  0.4155,  0.9849],\n",
       "          [ 0.2903,  0.0881, -1.3887,  ...,  1.2559, -0.0538, -0.3323],\n",
       "          ...,\n",
       "          [ 0.1021, -0.6484,  0.1062,  ..., -0.4558,  0.5088,  0.1423],\n",
       "          [ 0.0479, -0.0323,  0.4697,  ..., -0.9932,  0.1969,  0.6621],\n",
       "          [-0.2866, -0.4119,  0.9404,  ..., -2.2324,  0.1376,  0.4622]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.1024, -0.2998,  0.4697,  ..., -0.2527, -0.1868, -0.1216],\n",
       "          [ 0.1506, -1.0771, -0.0043,  ...,  0.5195,  0.6372,  0.9404],\n",
       "          [ 0.5078,  0.2891, -1.5693,  ...,  1.1025,  0.0848, -0.4678],\n",
       "          ...,\n",
       "          [-0.2151, -0.6904,  0.5439,  ..., -0.6616,  0.1587,  0.2004],\n",
       "          [-0.2350,  0.3538,  0.4048,  ..., -1.2002, -0.2191,  0.2363],\n",
       "          [ 0.0808, -0.2529,  1.0791,  ..., -3.0273, -0.1758,  0.3027]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.1207, -0.3159,  0.4995,  ..., -0.2627, -0.2322, -0.1096],\n",
       "          [ 0.2053, -1.1318, -0.1010,  ...,  0.4302,  0.6631,  1.1016],\n",
       "          [ 0.7368,  0.4482, -1.2930,  ...,  0.3105,  0.7080, -0.7764],\n",
       "          ...,\n",
       "          [ 0.0742, -1.1699,  0.4512,  ..., -1.4033, -0.0123,  0.8574],\n",
       "          [-0.0901, -0.3596, -0.3110,  ..., -1.6113, -0.7661,  0.2869],\n",
       "          [ 0.0297, -0.3110,  0.3086,  ..., -3.7461, -0.0767,  0.5869]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2203, -0.3896,  0.5029,  ..., -0.2021, -0.2153,  0.0257],\n",
       "          [ 0.1738, -0.9834, -0.3259,  ...,  0.6279,  0.6665,  1.3057],\n",
       "          [ 0.6318,  0.5488, -1.8398,  ...,  0.3938,  0.8765, -1.2852],\n",
       "          ...,\n",
       "          [ 0.5093, -0.8696,  0.2744,  ..., -1.2168, -0.1604,  1.1133],\n",
       "          [ 0.0420, -0.4155, -0.5776,  ..., -2.1797, -1.1572,  0.1633],\n",
       "          [-0.2954, -0.1005,  0.0085,  ..., -3.8008,  0.2568,  1.0781]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2382, -0.3779,  0.4966,  ..., -0.2537, -0.1190,  0.0859],\n",
       "          [ 0.4150, -1.1797, -0.4353,  ...,  0.7734,  0.9009,  1.4355],\n",
       "          [ 0.4819,  0.1631, -1.9629,  ...,  0.3374,  1.2070, -1.2363],\n",
       "          ...,\n",
       "          [ 0.1249, -0.7148,  0.1958,  ..., -1.5840, -0.5234,  1.2090],\n",
       "          [ 0.0735, -0.6636, -0.4050,  ..., -2.4570, -0.9224,  0.0833],\n",
       "          [ 0.5259, -0.3462, -0.1191,  ..., -3.5586, -0.4502,  0.9014]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2222, -0.4617,  0.5547,  ..., -0.2092, -0.2203,  0.0055],\n",
       "          [ 0.2959, -1.7422, -0.6509,  ...,  0.9727,  1.0088,  1.0859],\n",
       "          [ 0.4199,  0.1467, -2.1152,  ...,  0.3516,  1.5938, -1.9297],\n",
       "          ...,\n",
       "          [-0.2598, -0.2737,  1.0254,  ..., -1.1680,  0.2070,  0.7539],\n",
       "          [-0.6650, -0.3647, -0.0743,  ..., -2.2617, -1.3066, -0.4797],\n",
       "          [-0.2866, -0.5625, -0.4670,  ..., -4.1172, -0.1899,  0.2300]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.3669, -0.5420,  0.6147,  ..., -0.2483, -0.1219,  0.2200],\n",
       "          [ 0.2351, -2.0078, -0.4333,  ...,  0.9507,  1.2832,  1.0254],\n",
       "          [ 0.8770,  0.0883, -2.3789,  ...,  0.1538,  1.3711, -1.7246],\n",
       "          ...,\n",
       "          [-1.0117, -0.5103,  1.6895,  ..., -0.7803,  0.4651,  1.2734],\n",
       "          [-0.8584,  0.0981,  0.1650,  ..., -2.3047, -1.2920,  0.1406],\n",
       "          [-0.5410, -0.8315, -0.6050,  ..., -4.5000, -0.0742,  0.6255]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.4355, -0.5483,  0.6738,  ..., -0.1941, -0.0623,  0.0911],\n",
       "          [ 0.5063, -2.0234, -0.6279,  ...,  1.3848,  1.1855,  1.0947],\n",
       "          [ 0.7300,  0.0384, -3.2773,  ..., -0.3621,  0.4556, -1.3242],\n",
       "          ...,\n",
       "          [-0.4121, -0.6772,  1.7881,  ..., -0.6646,  0.8477,  0.7275],\n",
       "          [-0.8755, -0.1636,  0.1068,  ..., -2.5078, -1.1064,  0.4468],\n",
       "          [-0.8555, -1.0342, -0.8364,  ..., -4.7070, -0.0225,  0.5830]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.3655, -0.6880,  0.6025,  ..., -0.2220, -0.0163,  0.1082],\n",
       "          [ 0.1051, -2.3945, -0.5547,  ...,  1.8574,  1.9219,  1.1016],\n",
       "          [ 0.7236, -0.2329, -2.5469,  ..., -1.0967,  1.2480, -1.1338],\n",
       "          ...,\n",
       "          [-0.5078, -0.2478,  1.0303,  ..., -0.7251,  1.2236,  1.2012],\n",
       "          [-1.0859,  0.6191, -0.3657,  ..., -2.9102, -0.5806,  0.9248],\n",
       "          [-0.6196,  0.1396, -1.3867,  ..., -4.9844, -0.0568,  1.2148]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.4526, -0.7319,  0.6094,  ..., -0.1929,  0.0381,  0.1428],\n",
       "          [ 0.1138, -2.5918, -0.4502,  ...,  1.8965,  1.6836,  1.1494],\n",
       "          [ 0.4841, -0.3982, -2.4023,  ..., -0.6421,  1.0273, -0.6748],\n",
       "          ...,\n",
       "          [-1.0938, -0.5913,  1.3242,  ..., -1.4961,  0.6172,  1.3740],\n",
       "          [-1.1279,  0.2410, -0.8330,  ..., -3.2637, -1.5723,  1.1826],\n",
       "          [-1.3350, -0.0281, -1.8438,  ..., -5.5938, -0.7476,  0.5303]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.4688, -0.7324,  0.5957,  ..., -0.2310,  0.0312,  0.1963],\n",
       "          [ 0.3833, -2.5957,  0.0076,  ...,  1.7539,  1.7705,  1.0947],\n",
       "          [ 0.3147, -0.0791, -2.2793,  ..., -0.3584,  1.2471, -1.2344],\n",
       "          ...,\n",
       "          [-1.3379, -1.0342,  0.8613,  ..., -1.0508,  1.0586,  1.2891],\n",
       "          [-1.5332,  0.3687, -1.4346,  ..., -3.6484, -1.5469,  0.8799],\n",
       "          [-1.6719, -0.5723, -3.6660,  ..., -6.2734, -0.8535,  1.4375]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.3450, -0.7188,  0.6021,  ..., -0.2729,  0.1127,  0.2445],\n",
       "          [ 0.6904, -2.1367,  0.0174,  ...,  2.0840,  1.8350,  1.3242],\n",
       "          [ 0.6689, -0.4695, -2.4668,  ..., -0.4827,  1.2041, -1.0645],\n",
       "          ...,\n",
       "          [-0.9609, -0.8408,  1.0625,  ..., -0.4136,  1.4248,  1.2725],\n",
       "          [-1.4414,  0.2913, -1.5293,  ..., -3.4062, -1.0312,  1.7881],\n",
       "          [-0.9829, -1.1484, -5.2969,  ..., -7.0469, -0.0308,  2.5703]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2355, -0.7344,  0.4688,  ..., -0.3345,  0.1213,  0.3730],\n",
       "          [ 0.5723, -2.3965, -0.2925,  ...,  2.0645,  1.7666,  1.0361],\n",
       "          [ 1.0391,  0.0112, -3.0156,  ..., -0.1692,  1.5684, -1.2402],\n",
       "          ...,\n",
       "          [-1.8301, -0.4478,  0.5972,  ..., -0.8125,  1.9121,  0.9951],\n",
       "          [-1.6553,  0.2722, -2.6504,  ..., -3.2695, -0.9077,  2.0332],\n",
       "          [-0.5645, -1.0205, -5.5586,  ..., -6.5430,  0.8115,  2.2422]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.2441, -0.6919,  0.4980,  ..., -0.3372,  0.1792,  0.3179],\n",
       "          [ 0.5283, -2.2500,  0.0449,  ...,  2.1543,  2.2422,  1.4648],\n",
       "          [ 1.1982,  0.0905, -2.8496,  ..., -0.3528,  1.7842, -1.3145],\n",
       "          ...,\n",
       "          [-2.3672, -1.3887,  0.1675,  ..., -1.4736,  1.8770,  1.0137],\n",
       "          [-2.1719,  0.9912, -3.2754,  ..., -3.6328, -0.9707,  2.7422],\n",
       "          [-0.2717,  1.4492, -6.9766,  ..., -7.1641,  0.6055,  3.2031]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.3857, -0.7324,  0.4177,  ..., -0.3877,  0.1255,  0.4067],\n",
       "          [-0.0354, -2.1367, -0.2622,  ...,  2.2715,  2.4395,  1.1367],\n",
       "          [ 1.1533,  0.8916, -3.2871,  ..., -0.4282,  1.5469, -2.3965],\n",
       "          ...,\n",
       "          [-1.0010, -0.7393,  0.6680,  ...,  1.2559,  1.5166, -0.7446],\n",
       "          [-0.3594,  0.6265, -2.7188,  ..., -3.2969, -0.3662,  2.4844],\n",
       "          [-0.3584,  1.3301, -7.0586,  ..., -6.7383,  0.1655,  3.7539]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.4458, -0.8867,  0.4326,  ..., -0.5186,  0.1621,  0.4116],\n",
       "          [-0.4160, -2.2656, -0.1342,  ...,  2.2988,  2.2168,  0.9482],\n",
       "          [ 1.9629,  0.9956, -2.5977,  ..., -0.2603,  1.7637, -2.2051],\n",
       "          ...,\n",
       "          [-0.2495, -1.8584,  0.5278,  ...,  1.9258,  1.6494, -1.3477],\n",
       "          [-0.0381,  0.3467, -2.7715,  ..., -3.0879, -2.0664,  1.6348],\n",
       "          [ 0.3032,  0.4341, -7.2070,  ..., -7.2852, -1.0908,  1.3691]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.4253, -0.9321,  0.4563,  ..., -0.6338,  0.2341,  0.3567],\n",
       "          [-1.1494, -2.5273, -0.1991,  ...,  2.3125,  3.1816,  0.7139],\n",
       "          [ 2.1387,  0.3193, -1.1992,  ..., -0.1499,  1.5508, -2.8633],\n",
       "          ...,\n",
       "          [ 0.7256, -2.8535,  0.0857,  ...,  0.3174,  1.4414, -1.4023],\n",
       "          [ 0.7363, -0.3540, -3.1230,  ..., -4.3398, -1.4385,  2.5215],\n",
       "          [ 0.0461, -0.8101, -6.9727,  ..., -8.0703, -1.9297,  1.6328]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.5054, -0.9316,  0.5542,  ..., -0.6113,  0.1919,  0.5898],\n",
       "          [-1.5625, -2.6719,  0.5127,  ...,  1.8750,  3.4004,  1.7871],\n",
       "          [ 3.7031,  1.9404, -1.5830,  ..., -2.1016,  1.5713, -1.3887],\n",
       "          ...,\n",
       "          [ 1.5977, -4.3047, -0.1771,  ..., -0.4709, -0.7930, -1.0566],\n",
       "          [ 0.9458, -0.4524, -3.4512,  ..., -5.5781, -1.6016,  3.4961],\n",
       "          [ 0.0466, -3.6914, -7.6406,  ..., -7.7188, -1.7412,  1.4512]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[-0.3496, -0.7446,  0.3687,  ..., -0.6387,  0.0310,  0.1599],\n",
       "          [-1.0811, -1.8896,  0.8726,  ...,  1.9971,  3.9043,  0.5303],\n",
       "          [ 4.7461,  3.8242,  1.0176,  ..., -1.0234,  0.9609, -2.9570],\n",
       "          ...,\n",
       "          [ 5.5742, -0.8926, -0.7715,  ..., -0.6548, -1.0195, -2.5391],\n",
       "          [ 2.7656, -0.5879, -4.8438,  ..., -4.7734, -2.4160,  5.0898],\n",
       "          [-0.6250, -5.6484, -8.7031,  ..., -8.7969, -3.4043,  1.0869]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>),\n",
       " tensor([[[ 4.1641,  0.4851,  0.9390,  ..., -4.3047,  4.2305, -0.0548],\n",
       "          [-5.2500, -0.1947,  4.8906,  ...,  6.3750, -1.4268, -0.4421],\n",
       "          [ 0.2949, -3.8086,  1.9219,  ..., -1.8467, -3.1582, -1.6543],\n",
       "          ...,\n",
       "          [ 4.9102,  3.5430, -5.3828,  ..., -0.4983, -2.2246,  1.3535],\n",
       "          [ 5.0312, -2.0098, -5.0977,  ..., -2.2031, -1.2539,  5.3242],\n",
       "          [ 5.5938, -3.7598, -4.2734,  ..., -8.2812, -3.4355, -1.4033]]],\n",
       "        device='cuda:0', dtype=torch.float16, grad_fn=<ToCopyBackward0>))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a97b44-9783-465c-891f-313925e6ff3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
